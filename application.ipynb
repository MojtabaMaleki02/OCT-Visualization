{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "face1f69-56a7-4cef-aa90-95b01c96d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from construct import PaddedString, Int16un, Struct, Int32sn, Int32un, Int8un, Array\n",
    "from oct_converter.image_types import OCTVolumeWithMetaData, FundusImageWithMetaData\n",
    "from pathlib import Path\n",
    "\n",
    "class E2E(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = Path(filepath)\n",
    "        if not self.filepath.exists():\n",
    "            raise FileNotFoundError(self.filepath)\n",
    "        self.header_structure = Struct(\n",
    "            'magic1' / PaddedString(12, 'ascii'),\n",
    "            'version' / Int32un,\n",
    "            'unknown' / Array(10, Int16un)\n",
    "        )\n",
    "        self.main_directory_structure = Struct(\n",
    "            'magic2' / PaddedString(12, 'ascii'),\n",
    "            'version' / Int32un,\n",
    "            'unknown' / Array(10, Int16un),\n",
    "            'num_entries' / Int32un,\n",
    "            'current' / Int32un,\n",
    "            'prev' / Int32un,\n",
    "            'unknown3' / Int32un,\n",
    "        )\n",
    "        self.sub_directory_structure = Struct(\n",
    "            'pos' / Int32un,\n",
    "            'start' / Int32un,\n",
    "            'size' / Int32un,\n",
    "            'unknown' / Int32un,\n",
    "            'patient_id' / Int32un,\n",
    "            'study_id' / Int32un,\n",
    "            'series_id' / Int32un,\n",
    "            'slice_id' / Int32sn,\n",
    "            'unknown2' / Int16un,\n",
    "            'unknown3' / Int16un,\n",
    "            'type' / Int32un,\n",
    "            'unknown4' / Int32un,\n",
    "        )\n",
    "        self.chunk_structure = Struct(\n",
    "            'magic3' / PaddedString(12, 'ascii'),\n",
    "            'unknown' / Int32un,\n",
    "            'unknown2' / Int32un,\n",
    "            'pos' / Int32un,\n",
    "            'size' / Int32un,\n",
    "            'unknown3' / Int32un,\n",
    "            'patient_id' / Int32un,\n",
    "            'study_id' / Int32un,\n",
    "            'series_id' / Int32un,\n",
    "            'slice_id' / Int32sn,\n",
    "            'ind' / Int16un,\n",
    "            'unknown4' / Int16un,\n",
    "            'type' / Int32un,\n",
    "            'unknown5' / Int32un,\n",
    "        )\n",
    "        self.image_structure = Struct(\n",
    "            'size' / Int32un,\n",
    "            'type' / Int32un,\n",
    "            'unknown' / Int32un,\n",
    "            'width' / Int32un,\n",
    "            'height' / Int32un,\n",
    "        )\n",
    "        self.lat_structure = Struct(\n",
    "            'unknown' / Array(14, Int8un),\n",
    "            'laterality' / Int8un,\n",
    "            'unknown2' / Int8un\n",
    "        )\n",
    "\n",
    "        self.power = pow(2, 10)\n",
    "\n",
    "\n",
    "    def read_oct_volume(self):\n",
    "        def _make_lut():\n",
    "            LUT = []\n",
    "            for i in range(0,pow(2,16)):\n",
    "                LUT.append(self.uint16_to_ufloat16(i))\n",
    "            return np.array(LUT)\n",
    "        LUT = _make_lut() \n",
    "               \n",
    "\n",
    "        with open(self.filepath, 'rb') as f:\n",
    "            raw = f.read(36)\n",
    "            header = self.header_structure.parse(raw)\n",
    "\n",
    "            raw = f.read(52)\n",
    "            main_directory = self.main_directory_structure.parse(raw)\n",
    "\n",
    "            # traverse list of main directories in first pass\n",
    "            directory_stack = []\n",
    "\n",
    "            current = main_directory.current\n",
    "            while current != 0:\n",
    "                directory_stack.append(current)\n",
    "                f.seek(current)\n",
    "                raw = f.read(52)\n",
    "                directory_chunk = self.main_directory_structure.parse(raw)\n",
    "                current = directory_chunk.prev\n",
    "\n",
    "            # traverse in second pass and  get all subdirectories\n",
    "            chunk_stack = []\n",
    "            volume_dict = {}\n",
    "            for position in directory_stack:\n",
    "                f.seek(position)\n",
    "                raw = f.read(52)\n",
    "                directory_chunk = self.main_directory_structure.parse(raw)\n",
    "\n",
    "                for ii in range(directory_chunk.num_entries):\n",
    "                    raw = f.read(44)\n",
    "                    chunk = self.sub_directory_structure.parse(raw)\n",
    "                    volume_string = '{}_{}_{}'.format(chunk.patient_id, chunk.study_id, chunk.series_id)\n",
    "                    if volume_string not in volume_dict.keys():\n",
    "                        volume_dict[volume_string] = chunk.slice_id / 2\n",
    "                    elif chunk.slice_id / 2 > volume_dict[volume_string]:\n",
    "                        volume_dict[volume_string] = chunk.slice_id / 2\n",
    "\n",
    "                    if chunk.start > chunk.pos:\n",
    "                        chunk_stack.append([chunk.start, chunk.size])\n",
    "\n",
    "            # initalise dict to hold all the image volumes\n",
    "            volume_array_dict = {}\n",
    "            volume_array_dict_additional = {} # for storage of slices not caught by extraction\n",
    "            for volume, num_slices in volume_dict.items():\n",
    "                if num_slices > 0:\n",
    "                    # num_slices + 1 here due to evidence that a slice was being missed off the end in extraction\n",
    "                    volume_array_dict[volume] = [0] * int(num_slices + 1)\n",
    "\n",
    "            # traverse all chunks and extract slices\n",
    "            for start, pos in chunk_stack:\n",
    "                f.seek(start)\n",
    "                raw = f.read(60)\n",
    "                chunk = self.chunk_structure.parse(raw)\n",
    "\n",
    "                if chunk.type == 11:  # laterality data\n",
    "                    raw = f.read(20)\n",
    "                    try:\n",
    "                        laterality_data = self.lat_structure.parse(raw)\n",
    "                        if laterality_data.laterality == 82:\n",
    "                            self.laterality = 'R'\n",
    "                        elif laterality_data.laterality == 76:\n",
    "                            self.laterality = 'L'\n",
    "                    except:\n",
    "                        self.laterality = None\n",
    "\n",
    "                if chunk.type == 1073741824:  # image data\n",
    "                    raw = f.read(20)\n",
    "                    image_data = self.image_structure.parse(raw)\n",
    "\n",
    "                    if chunk.ind == 1:  # oct data\n",
    "                        raw_volume = np.fromfile(f, dtype=np.uint16, count=image_data.height * image_data.width)\n",
    "                        image = LUT[raw_volume].reshape(image_data.width, image_data.height)\n",
    "                        image = 256 * pow(image, 1.0 / 2.4)\n",
    "                        volume_string = '{}_{}_{}'.format(chunk.patient_id, chunk.study_id, chunk.series_id)\n",
    "                        if volume_string in volume_array_dict.keys():\n",
    "                            volume_array_dict[volume_string][int(chunk.slice_id / 2) - 1] = image\n",
    "                        else:\n",
    "                            # try to capture these additional images\n",
    "                            if volume_string in volume_array_dict_additional.keys():\n",
    "                                volume_array_dict_additional[volume_string].append(image)\n",
    "                            else:\n",
    "                                volume_array_dict_additional[volume_string] = [image]\n",
    "                            #print('Failed to save image data for volume {}'.format(volume_string))\n",
    "\n",
    "            oct_volumes = []\n",
    "            for key, volume in volume_array_dict.items():\n",
    "                oct_volumes.append(OCTVolumeWithMetaData(volume=volume, patient_id=key, laterality=self.laterality))\n",
    "            for key, volume in volume_array_dict_additional.items():\n",
    "                oct_volumes.append(OCTVolumeWithMetaData(volume=volume, patient_id=key, laterality=self.laterality))\n",
    "\n",
    "        return oct_volumes\n",
    "\n",
    "    def read_fundus_image(self):\n",
    "        with open(self.filepath, 'rb') as f:\n",
    "            raw = f.read(36)\n",
    "            header = self.header_structure.parse(raw)\n",
    "\n",
    "            raw = f.read(52)\n",
    "            main_directory = self.main_directory_structure.parse(raw)\n",
    "\n",
    "            # traverse list of main directories in first pass\n",
    "            directory_stack = []\n",
    "\n",
    "            current = main_directory.current\n",
    "            while current != 0:\n",
    "                directory_stack.append(current)\n",
    "                f.seek(current)\n",
    "                raw = f.read(52)\n",
    "                directory_chunk = self.main_directory_structure.parse(raw)\n",
    "                current = directory_chunk.prev\n",
    "\n",
    "            # traverse in second pass and  get all subdirectories\n",
    "            chunk_stack = []\n",
    "            for position in directory_stack:\n",
    "                f.seek(position)\n",
    "                raw = f.read(52)\n",
    "                directory_chunk = self.main_directory_structure.parse(raw)\n",
    "\n",
    "                for ii in range(directory_chunk.num_entries):\n",
    "                    raw = f.read(44)\n",
    "                    chunk = self.sub_directory_structure.parse(raw)\n",
    "                    if chunk.start > chunk.pos:\n",
    "                        chunk_stack.append([chunk.start, chunk.size])\n",
    "\n",
    "            # initalise dict to hold all the image volumes\n",
    "            image_array_dict = {}\n",
    "\n",
    "            # traverse all chunks and extract slices\n",
    "            for start, pos in chunk_stack:\n",
    "                f.seek(start)\n",
    "                raw = f.read(60)\n",
    "                chunk = self.chunk_structure.parse(raw)\n",
    "\n",
    "                if chunk.type == 11:  # laterality data\n",
    "                    raw = f.read(20)\n",
    "                    try:\n",
    "                        laterality_data = self.lat_structure.parse(raw)\n",
    "                        if laterality_data.laterality == 82:\n",
    "                            self.laterality = 'R'\n",
    "                        elif laterality_data.laterality == 76:\n",
    "                            self.laterality = 'L'\n",
    "                    except:\n",
    "                        self.laterality = None\n",
    "\n",
    "                if chunk.type == 1073741824:  # image data\n",
    "                    raw = f.read(20)\n",
    "                    image_data = self.image_structure.parse(raw)\n",
    "\n",
    "                    if chunk.ind == 0:  # fundus data\n",
    "                        raw_volume = np.fromstring(f.read(image_data.height * image_data.width), dtype=np.uint8)\n",
    "                        image = np.array(raw_volume).reshape(image_data.height,image_data.width)\n",
    "                        image_string = '{}_{}_{}'.format(chunk.patient_id, chunk.study_id, chunk.series_id)\n",
    "                        image_array_dict[image_string] = image\n",
    "\n",
    "\n",
    "            fundus_images = []\n",
    "            for key, image in image_array_dict.items():\n",
    "                fundus_images.append(FundusImageWithMetaData(image=image, patient_id=key, laterality= self.laterality))\n",
    "\n",
    "        return fundus_images\n",
    "\n",
    "    def read_custom_float(self, bytes):\n",
    "\n",
    "        # convert two bytes to 16-bit binary representation\n",
    "        bits = bin(bytes[0])[2:].zfill(8)[::-1] + bin(bytes[1])[2:].zfill(8)[::-1]\n",
    "\n",
    "        # get mantissa and exponent\n",
    "        mantissa = bits[:10]\n",
    "        exponent = bits[10:]\n",
    "\n",
    "        # convert to decimal representations\n",
    "        mantissa_sum = 1 + int(mantissa, 2) / self.power\n",
    "        exponent_sum = int(exponent[::-1], 2) - 63\n",
    "        decimal_value = mantissa_sum * pow(2, exponent_sum)\n",
    "        return decimal_value\n",
    "\n",
    "    def uint16_to_ufloat16(self, uint16):\n",
    "\n",
    "        bits = '{0:016b}'.format(uint16)[::-1]\n",
    "        # get mantissa and exponent\n",
    "        mantissa = bits[:10]\n",
    "        exponent = bits[10:]\n",
    "        exponent = exponent[::-1]\n",
    "\n",
    "        # convert to decimal representations\n",
    "        mantissa_sum = 1 + int(mantissa, 2) / self.power\n",
    "        exponent_sum = int(exponent, 2) - 63\n",
    "        decimal_value = mantissa_sum * np.float_power(2, exponent_sum)\n",
    "        return decimal_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22b2f07-8fe5-440f-8fa4-3e62953745f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def saveImages():\n",
    "    # Create the 'images' directory if it doesn't exist\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "    \n",
    "    # Save OCT volume images\n",
    "    for i, oct_volume in enumerate(oct_volumes):\n",
    "        if i != 0:\n",
    "            break\n",
    "        for j, image in enumerate(oct_volume.volume):\n",
    "            if image is not None:\n",
    "                # Convert the image to uint8 (from float) for saving\n",
    "                image_uint8 = (image / np.max(image) * 255).astype(np.uint8)\n",
    "                img = Image.fromarray(image_uint8)\n",
    "                img.save(f'images/oct_volume_{i}_slice_{j}.png')\n",
    "    \n",
    "    print(\"Images saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082a1962-b329-4ebb-b40d-02767767d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moji\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading OCT volume from C:/Users/Moji/Desktop/Acél Ede/ACEL01E.E2E\n",
      "Reading fundus images from C:/Users/Moji/Desktop/Acél Ede/ACEL01E.E2E\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import vtk\n",
    "from skimage import io, transform, measure, filters\n",
    "import concurrent.futures\n",
    "\n",
    "# Create the 'images' directory if it doesn't exist\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "class E2E:\n",
    "    \"\"\"Placeholder class for handling .e2e file operations\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def read_oct_volume(self):\n",
    "        # Placeholder for actual OCT volume reading logic\n",
    "        print(f\"Reading OCT volume from {self.file_path}\")\n",
    "        return np.random.rand(100, 100, 100)  # Dummy data for demonstration\n",
    "\n",
    "    def read_fundus_image(self):\n",
    "        # Placeholder for actual fundus image reading logic\n",
    "        print(f\"Reading fundus images from {self.file_path}\")\n",
    "        return np.random.rand(512, 512)  # Dummy data for demonstration\n",
    "\n",
    "\n",
    "class ImageProcessor:\n",
    "\n",
    "    @staticmethod\n",
    "    def process_folder(folder_path, scale_factor, z_scale_factor):\n",
    "\n",
    "        npz_dir = \"NPZ_files\"\n",
    "        os.makedirs(npz_dir, exist_ok=True)\n",
    "\n",
    "        file_paths = ImageProcessor._get_image_files(folder_path)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            slices = list(executor.map(lambda f: ImageProcessor._load_and_rescale_image(f, scale_factor), file_paths))\n",
    "\n",
    "        slices = np.array(slices)\n",
    "\n",
    "        # Adjust the sigma value to preserve more details\n",
    "        slices = filters.gaussian(slices, sigma=1.0)\n",
    "\n",
    "        # Get the min and max intensity values for dynamic thresholding\n",
    "        min_intensity = np.min(slices)\n",
    "        max_intensity = np.max(slices)\n",
    "\n",
    "        # Set a dynamic threshold as a fraction of the intensity range\n",
    "        threshold = min_intensity + 0.5 * (max_intensity - min_intensity)\n",
    "\n",
    "        spacing = (z_scale_factor, 1.0, 1.0)\n",
    "\n",
    "        # Perform marching cubes within the intensity range\n",
    "        vertices, faces, _, _ = measure.marching_cubes(slices, level=threshold, spacing=spacing)\n",
    "\n",
    "        folder_name = os.path.basename(folder_path)\n",
    "        npz_file_path = os.path.join(npz_dir, f\"{folder_name}.npz\")\n",
    "        np.savez(npz_file_path, vertices=vertices, faces=faces, slices=slices)\n",
    "\n",
    "        return npz_file_path\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_and_rescale_image(file_path, scale_factor):\n",
    "\n",
    "        img = io.imread(file_path, as_gray=True)\n",
    "        return transform.rescale(img, scale_factor, anti_aliasing=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_image_files(folder_path):\n",
    "\n",
    "        file_paths = [os.path.join(\"images\", filename)\n",
    "                      for filename in sorted(os.listdir(\"images\"))\n",
    "                      if filename.endswith(\".png\")]\n",
    "\n",
    "        if not file_paths:\n",
    "            raise ValueError(\"No PNG images found in the selected folder.\")\n",
    "        return file_paths\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_3d(npz_file_path, slice_start, slice_end):\n",
    "        try:\n",
    "            data = np.load(npz_file_path)\n",
    "            vertices = data['vertices']\n",
    "            faces = data['faces']\n",
    "            slices = data['slices']\n",
    "\n",
    "            # Limit the slices to the specified range\n",
    "            limited_slices = slices[slice_start:slice_end + 1]\n",
    "            min_intensity = np.min(limited_slices)\n",
    "            max_intensity = np.max(limited_slices)\n",
    "\n",
    "            # Create the 3D model for the selected slices\n",
    "            spacing = (1.0, 1.0, 1.0)\n",
    "            threshold = min_intensity + 0.5 * (max_intensity - min_intensity)\n",
    "\n",
    "            vertices, faces, _, _ = measure.marching_cubes(limited_slices, level=threshold, spacing=spacing)\n",
    "\n",
    "            points = vtk.vtkPoints()\n",
    "            for vertex in vertices:\n",
    "                points.InsertNextPoint(vertex)\n",
    "\n",
    "            polydata = vtk.vtkPolyData()\n",
    "            polydata.SetPoints(points)\n",
    "\n",
    "            faces_array = vtk.vtkCellArray()\n",
    "            for face in faces:\n",
    "                triangle = vtk.vtkTriangle()\n",
    "                for i in range(3):\n",
    "                    triangle.GetPointIds().SetId(i, face[i])\n",
    "                faces_array.InsertNextCell(triangle)\n",
    "\n",
    "            polydata.SetPolys(faces_array)\n",
    "\n",
    "            # Add color mapping to enhance visualization\n",
    "            mapper = vtk.vtkPolyDataMapper()\n",
    "            mapper.SetInputData(polydata)\n",
    "            mapper.ScalarVisibilityOn()  # Enable scalar visibility for color mapping\n",
    "\n",
    "            # Create a lookup table to assign colors to different scalar values\n",
    "            lut = vtk.vtkLookupTable()\n",
    "            lut.SetTableRange(vertices.min(), vertices.max())\n",
    "            lut.Build()\n",
    "\n",
    "            mapper.SetLookupTable(lut)\n",
    "            mapper.SetScalarRange(vertices.min(), vertices.max())\n",
    "\n",
    "            actor = vtk.vtkActor()\n",
    "            actor.SetMapper(mapper)\n",
    "\n",
    "            renderer = vtk.vtkRenderer()\n",
    "            renderer.AddActor(actor)\n",
    "\n",
    "            render_window = vtk.vtkRenderWindow()\n",
    "            render_window.AddRenderer(renderer)\n",
    "\n",
    "            interactor = vtk.vtkRenderWindowInteractor()\n",
    "            interactor.SetRenderWindow(render_window)\n",
    "\n",
    "            renderer.ResetCamera()\n",
    "            render_window.Render()\n",
    "            interactor.Start()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error during visualization: {e}\")\n",
    "\n",
    "\n",
    "class ImageProcessingApp:\n",
    "    \"\"\"Main application for image processing with a Tkinter GUI.\"\"\"\n",
    "\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"3D Image Processor\")\n",
    "\n",
    "        self._init_ui()\n",
    "\n",
    "        self.e2e_file_path = None\n",
    "        self.npz_file_path = None\n",
    "\n",
    "    def _init_ui(self):\n",
    "        \"\"\"Initializes the UI components.\"\"\"\n",
    "        self.scale_label = tk.Label(self.master, text=\"Scale Factor (XY):\")\n",
    "        self.scale_label.pack()\n",
    "        self.scale_slider = tk.Scale(self.master, from_=0.1, to=1.0, resolution=0.01, orient=\"horizontal\")\n",
    "        self.scale_slider.set(0.25)\n",
    "        self.scale_slider.pack()\n",
    "\n",
    "        self.z_scale_label = tk.Label(self.master, text=\"Z-Scale Factor:\")\n",
    "        self.z_scale_label.pack()\n",
    "        self.z_scale_slider = tk.Scale(self.master, from_=0.5, to=5.0, resolution=0.1, orient=\"horizontal\")\n",
    "        self.z_scale_slider.set(1.0)\n",
    "        self.z_scale_slider.pack()\n",
    "\n",
    "        self.slice_start_label = tk.Label(self.master, text=\"Start Slice:\")\n",
    "        self.slice_start_label.pack()\n",
    "        self.slice_start_slider = tk.Scale(self.master, from_=0, to=24, orient=\"horizontal\")\n",
    "        self.slice_start_slider.set(0)\n",
    "        self.slice_start_slider.pack()\n",
    "\n",
    "        self.slice_end_label = tk.Label(self.master, text=\"End Slice:\")\n",
    "        self.slice_end_label.pack()\n",
    "        self.slice_end_slider = tk.Scale(self.master, from_=0, to=24, orient=\"horizontal\")\n",
    "        self.slice_end_slider.set(24)\n",
    "        self.slice_end_slider.pack()\n",
    "\n",
    "        self.e2e_button = tk.Button(self.master, text=\"Select E2E File\", command=self.select_e2e_file)\n",
    "        self.e2e_button.pack()\n",
    "\n",
    "        self.process_button = tk.Button(self.master, text=\"Process Images\", command=self.process_images)\n",
    "        self.process_button.pack()\n",
    "\n",
    "    def select_e2e_file(self):\n",
    "        \"\"\"Handles .e2e file selection.\"\"\"\n",
    "        self.e2e_file_path = filedialog.askopenfilename(filetypes=[(\"E2E files\", \"*.E2E\")])\n",
    "        if self.e2e_file_path:\n",
    "            messagebox.showinfo(\"File Selected\", f\"Selected file: {self.e2e_file_path}\")\n",
    "\n",
    "    def process_images(self):\n",
    "        \"\"\"Processes images and visualizes them in 3D.\"\"\"\n",
    "        if not self.e2e_file_path:\n",
    "            messagebox.showwarning(\"No E2E File\", \"Please select an E2E file first.\")\n",
    "            return\n",
    "\n",
    "        scale_factor = self.scale_slider.get()\n",
    "        z_scale_factor = self.z_scale_slider.get()\n",
    "\n",
    "        try:\n",
    "            e2e = E2E(self.e2e_file_path)\n",
    "            oct_volumes = e2e.read_oct_volume()  # Reading OCT volume\n",
    "            fundus_images = e2e.read_fundus_image()  # Reading fundus images\n",
    "\n",
    "            self.npz_file_path = ImageProcessor.process_folder(self.e2e_file_path, scale_factor, z_scale_factor)\n",
    "            messagebox.showinfo(\"Processing Complete\", f\"Saved processed data to: {self.npz_file_path}\")\n",
    "\n",
    "            # Get slice start and end from sliders\n",
    "            slice_start = self.slice_start_slider.get()\n",
    "            slice_end = self.slice_end_slider.get()\n",
    "\n",
    "            # Call visualization for the selected slice range\n",
    "            Visualizer.visualize_3d(self.npz_file_path, slice_start, slice_end)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Processing Error\", str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ImageProcessingApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaec3f-b12e-4e70-8a68-ef5b779e39e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
